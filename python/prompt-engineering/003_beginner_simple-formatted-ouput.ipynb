{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be0408d6",
   "metadata": {},
   "source": [
    "# Formatted output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c478d9",
   "metadata": {},
   "source": [
    "Author: Pavel Agurov, pavel_agurov@epam.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3f7cf7",
   "metadata": {},
   "source": [
    "In this example we will ask model to generate output not just a text, but in XML or JSON format.\n",
    "\n",
    "The idea of this code is to compare 2 text list and build pairs. To have some explanation we will ask model to provide not only pairs, but score and explanation. It allows us to build not \"black box\" solution, but have some \"inside\" from model.\n",
    "\n",
    "LLM works good with both formats (and also support many other - CSV, YAML). You can make a choise based on your data. For example if you expect long text in the output - XML can be better, because JSON is too fragile and can be easy corrupted during long output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18e1bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai > /dev/null\n",
    "%pip install tiktoken > /dev/null\n",
    "%pip install langchain > /dev/null\n",
    "%pip install langchain_openai > /dev/null\n",
    "%pip install langchain_core > /dev/null\n",
    "%pip install langchain_community > /dev/null\n",
    "%pip install langchain_text_splitters > /dev/null\n",
    "%pip install sentence-transformers > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7324405",
   "metadata": {},
   "source": [
    "## Prompt\n",
    "\n",
    "First we will build prompt. There are many ways how we can create prompt, but in simplest case it's just string with parameters. We will build 2 versions of prompt - with XML output and JSON output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2900c99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "COMPARE_PROMPT_TEMPLATE = \"\"\"\n",
    "Your task is to find the best pairs between 2 string lists if possible.\n",
    "If you can't build pair for the item - just say \"no pair\".\n",
    "Be sure that you read all items from first list.\n",
    "Be sure that you check ALL items from second list and found the best fit.\n",
    "\n",
    "<first_list>\n",
    "{first_list}\n",
    "</first_list>\n",
    "\n",
    "<second_list>\n",
    "{second_list}\n",
    "</second_list>\n",
    "\n",
    "Pair list in XML format:\n",
    "<paired_list>\n",
    "  <pair>\n",
    "    <first_item>first item</first_item>\n",
    "    <second_item>relevant item if exist or say 'no pair'</second_item>\n",
    "    <score>score of relevance</score>\n",
    "    <explanation>explain your decision</explanation>\n",
    "  </pair>\n",
    "</paired_list>\n",
    "\"\"\"\n",
    "\n",
    "xml_prompt = ChatPromptTemplate.from_template(COMPARE_PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d52ad2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "COMPARE_PROMPT_TEMPLATE = \"\"\"\n",
    "Your task is to find the best pairs between 2 string lists if possible.\n",
    "If you can't build pair for the item - just say \"no pair\".\n",
    "Be sure that you read all items from first list.\n",
    "Be sure that you check ALL items from second list and found the best fit.\n",
    "\n",
    "<first_list>\n",
    "{first_list}\n",
    "</first_list>\n",
    "\n",
    "<second_list>\n",
    "{second_list}\n",
    "</second_list>\n",
    "\n",
    "Pair list in JSON format:\n",
    "[\n",
    "  \"pair\": {{\n",
    "    \"first_item\": \"first item\",\n",
    "    \"second_item\": \"relevant item if exist or say 'no pair'\",\n",
    "    \"score\": score of relevance,\n",
    "    \"explanation\": \"explain your decision\"  \n",
    "  }}\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "json_prompt = ChatPromptTemplate.from_template(COMPARE_PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34296553",
   "metadata": {},
   "source": [
    "## LLM model\n",
    "\n",
    "Model should be powerful enough to be able to provide relevant result, but from another side - has reasonable price to make result profitable.\n",
    "\n",
    "Remember about temperature parameter - in langchain by default it's not 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "861ca4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "        api_key         = os.environ['OPENAI_API_KEY'],\n",
    "        api_version     = \"2023-07-01-preview\",\n",
    "        azure_endpoint  = \"https://ai-proxy.lab.epam.com\",\n",
    "        model           = \"gpt-4o-mini-2024-07-18\",\n",
    "        temperature     = 0.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00433207",
   "metadata": {},
   "source": [
    "## Chains: XML and JSON\n",
    "\n",
    "You combile prompt, model and output parser into one chain. We use StrOutputParser because we will parse result manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73901dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "xml_chain  = xml_prompt  | llm | StrOutputParser()\n",
    "json_chain = json_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077e0e84",
   "metadata": {},
   "source": [
    "## Run\n",
    "\n",
    "- get_openai_callback here allows to have count of used tokens\n",
    "- function create_list creates list of string\n",
    "- call_llm will call LLM with invoke method and return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e22381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.callbacks import get_openai_callback\n",
    "\n",
    "def call_llm(chain, first_list : str, second_list : str) -> tuple[str, int]:\n",
    "    with get_openai_callback() as cb:\n",
    "        llm_result = chain.invoke({\n",
    "                \"first_list\"   : first_list, \n",
    "                \"second_list\"  : second_list\n",
    "            })\n",
    "        return llm_result, cb.total_tokens\n",
    "    \n",
    "def create_list(str_array : list[str]) -> str:\n",
    "    return \"\".join([f\"- {s}\\n\" for s in str_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77c85a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_input_list  = create_list(\n",
    "    ['cat', 'dog', 'apple', 'computer']\n",
    ")\n",
    "second_input_list = create_list(\n",
    "    ['mouse', 'orange', 'shepherd']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1f2e3d",
   "metadata": {},
   "source": [
    "Let's run XML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ce2e357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used tokens: 442\n"
     ]
    },
    {
     "ename": "ParseError",
     "evalue": "not well-formed (invalid token): line 1, column 0 (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
      "  File \u001b[92m~/git/programming/python/prompt-engineering/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3699\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Cell \u001b[92mIn[7]\u001b[39m\u001b[92m, line 5\u001b[39m\n    parsed_xml = ET.ElementTree(ET.fromstring(xml_result))\n",
      "\u001b[36m  \u001b[39m\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/xml/etree/ElementTree.py:1342\u001b[39m\u001b[36m in \u001b[39m\u001b[35mXML\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mparser.feed(text)\u001b[39m\n",
      "  \u001b[36mFile \u001b[39m\u001b[32m<string>\u001b[39m\n\u001b[31mParseError\u001b[39m\u001b[31m:\u001b[39m not well-formed (invalid token): line 1, column 0\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "xml_result, tokens_used = call_llm(xml_chain, first_input_list, second_input_list)\n",
    "print(f\"Used tokens: {tokens_used}\")\n",
    "parsed_xml = ET.ElementTree(ET.fromstring(xml_result))\n",
    "\n",
    "ET.dump(parsed_xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e99e787",
   "metadata": {},
   "source": [
    "Let's run JSON code. If you have crash - do not be surprised, it can happened after first or maybe after thousandth run.\n",
    "Below you can find instruction how to fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fae837e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used tokens: 404\n",
      "[\n",
      "    {\n",
      "        \"pair\": {\n",
      "            \"first_item\": \"cat\",\n",
      "            \"second_item\": \"no pair\",\n",
      "            \"score\": 0,\n",
      "            \"explanation\": \"There is no relevant item in the second list for 'cat'.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"pair\": {\n",
      "            \"first_item\": \"dog\",\n",
      "            \"second_item\": \"shepherd\",\n",
      "            \"score\": 0.5,\n",
      "            \"explanation\": \"The word 'dog' can be associated with 'shepherd' as it is a type of dog breed.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"pair\": {\n",
      "            \"first_item\": \"apple\",\n",
      "            \"second_item\": \"no pair\",\n",
      "            \"score\": 0,\n",
      "            \"explanation\": \"There is no relevant item in the second list for 'apple'.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"pair\": {\n",
      "            \"first_item\": \"computer\",\n",
      "            \"second_item\": \"mouse\",\n",
      "            \"score\": 0.6,\n",
      "            \"explanation\": \"The word 'computer' can be associated with 'mouse' as it is a peripheral device used with computers.\"\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_result, tokens_used = call_llm(json_chain, first_input_list, second_input_list)\n",
    "print(f\"Used tokens: {tokens_used}\")\n",
    "parsed_json = json.loads(json_result)\n",
    "print(json.dumps(parsed_json, indent = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73e6c6d",
   "metadata": {},
   "source": [
    "You should take into account that LLM can't garantee always correct format of output. Both XML and JSON can be corrupted.\n",
    "In some cases you can easy restore it, but in some cases you can't or should have new prompt to ask LLM to fix issues.\n",
    "\n",
    "Refs: https://api.python.langchain.com/en/latest/output_parsers/langchain.output_parsers.retry.RetryWithErrorOutputParser.html#\n",
    "\n",
    "Functions below are helpful if you want to fix JSON in simplest way without additional calls to LLM (it takes time and money)\n",
    "\n",
    "You can also check open-source project https://github.com/josdejong/jsonrepair - it allows to fix most of cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7279494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_noise_from_json(json_str: str) -> str:\n",
    "    \"\"\"\n",
    "        Remove all text before fist { and after last }\n",
    "        For examle to remove text noise:\n",
    "           Your JSON {....}. Welcome!  --> json only\n",
    "    \"\"\"\n",
    "    fist_bracket1_index = json_str.index(\"{\")\n",
    "    last_bracket1_index = json_str.rindex(\"}\")\n",
    "    \n",
    "    fist_bracket2_index = json_str.index(\"[\")\n",
    "    last_bracket2_index = json_str.rindex(\"]\")\n",
    "\n",
    "    # we need first bracket if exists    \n",
    "    if fist_bracket1_index >=0 and fist_bracket2_index >=0:\n",
    "        fist_bracket_index = min(fist_bracket1_index, fist_bracket2_index)\n",
    "    else:\n",
    "        fist_bracket_index = max(fist_bracket1_index, fist_bracket2_index)\n",
    "        \n",
    "    # we need last bracket if exists\n",
    "    last_bracket_index = max(last_bracket1_index, last_bracket2_index)\n",
    "    \n",
    "    if fist_bracket_index != -1 and last_bracket_index != -1:\n",
    "        return json_str[fist_bracket_index:last_bracket_index+1]\n",
    "    return json_str\n",
    "\n",
    "    \n",
    "def fix_non_json_chars(json_str: str) -> str:\n",
    "    \"\"\"\n",
    "        Fix non json chars in json if possible\n",
    "    \"\"\"\n",
    "    json_str = json_str.replace(\"\\\\\\\"\", '\\'')\n",
    "    json_str = json_str.replace(\"\\\\\", '\\\\\\\\')\n",
    "    json_str = json_str.replace('\\n', ' ')\n",
    "    json_str = re.sub(r\"},\\s*]\", \"}]\", json_str)\n",
    "    json_str = re.sub(r\"}\\s*{\", \"},{\", json_str)\n",
    "    \n",
    "    return json_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f1711d",
   "metadata": {},
   "source": [
    "In our simple case we can have no problem with JSON output, but if we have long text it's possible that quotes will be in output and we can't parse result. In this case we recommend to replace all types of quotes to the single quote BEFORE call LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bc34b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_text(text : str) -> str:\n",
    "    \"\"\"Remove dagerous for JSON chars from text\"\"\"\n",
    "    return text.replace(\"“\", \"'\").replace(\"“\", \"”\").replace(\"\\\"\", \"'\").replace(\"«\", \"'\").replace(\"»\", \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88fc6fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used tokens: 389\n",
      "[\n",
      "    {\n",
      "        \"pair\": {\n",
      "            \"first_item\": \"cat\",\n",
      "            \"second_item\": \"no pair\",\n",
      "            \"score\": 0,\n",
      "            \"explanation\": \"There is no relevant item in the second list for 'cat'.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"pair\": {\n",
      "            \"first_item\": \"dog\",\n",
      "            \"second_item\": \"shepherd\",\n",
      "            \"score\": 0.5,\n",
      "            \"explanation\": \"The word 'dog' is related to 'shepherd' as a breed of dog.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"pair\": {\n",
      "            \"first_item\": \"apple\",\n",
      "            \"second_item\": \"orange\",\n",
      "            \"score\": 0.67,\n",
      "            \"explanation\": \"Both 'apple' and 'orange' are fruits.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"pair\": {\n",
      "            \"first_item\": \"computer\",\n",
      "            \"second_item\": \"mouse\",\n",
      "            \"score\": 0.6,\n",
      "            \"explanation\": \"A 'mouse' is a peripheral device used with a computer.\"\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# remove dagerous chars from input\n",
    "fixed_first_input_list  = clean_up_text(first_input_list)\n",
    "fixed_second_input_list = clean_up_text(second_input_list)\n",
    "\n",
    "# run LLM\n",
    "json_result, tokens_used = call_llm(json_chain, fixed_first_input_list, fixed_second_input_list)\n",
    "print(f\"Used tokens: {tokens_used}\")\n",
    "\n",
    "# let's fix json to avoid problems\n",
    "json_result = remove_noise_from_json(json_result)\n",
    "json_result = fix_non_json_chars(json_result)\n",
    "\n",
    "# now we can parse it\n",
    "parsed_json = json.loads(json_result)\n",
    "print(json.dumps(parsed_json, indent = 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
